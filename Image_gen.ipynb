{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ3kjW7THqZ6"
      },
      "outputs": [],
      "source": [
        "# MULTI-USER AI IMAGE LAB\n",
        "\n",
        "# -------- INSTALL ----------\n",
        "!pip install diffusers transformers accelerate safetensors pillow torch gradio -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- IMPORTS ----------\n",
        "import torch, os, uuid\n",
        "import gradio as gr\n",
        "from PIL import Image, ImageEnhance\n",
        "from diffusers import (\n",
        "    StableDiffusionPipeline,\n",
        "    StableDiffusionImg2ImgPipeline,\n",
        "    EulerAncestralDiscreteScheduler\n",
        ")\n",
        "\n",
        "#  STEP 3: Hugging Face Token (Required for Diffusers)\n",
        "HUGGING_FACE_TOKEN = \"\"  # Replace if expired\n",
        "HUGGING_FACE_TOKEN = \"\"  # Replace if expired"
      ],
      "metadata": {
        "id": "38RadPx0HxqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- SYSTEM CONFIG ----------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DTYPE = torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
        "IMG_SIZE = 768\n",
        "UPSCALE_SIZE = 2048\n",
        "\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "# -------- MODEL INITIALIZATION ----------\n",
        "def load_scheduler():\n",
        "    return EulerAncestralDiscreteScheduler.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        subfolder=\"scheduler\"\n",
        "    )\n",
        "\n",
        "def load_pipelines(scheduler):\n",
        "    txt_pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        scheduler=scheduler,\n",
        "        torch_dtype=DTYPE\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    img_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        scheduler=scheduler,\n",
        "        torch_dtype=DTYPE\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    txt_pipe.enable_attention_slicing()\n",
        "    img_pipe.enable_attention_slicing()\n",
        "\n",
        "    return txt_pipe, img_pipe\n",
        "\n",
        "scheduler = load_scheduler()\n",
        "txt2img, img2img = load_pipelines(scheduler)\n",
        "\n",
        "# -------- QUALITY FILTER ----------\n",
        "NEGATIVE_FILTER = (\n",
        "    \"blurry, low quality, distorted anatomy, bad hands, \"\n",
        "    \"watermark, text, logo, oversharpen, noisy background\"\n",
        ")\n",
        "\n",
        "# -------- IMAGE PIPELINE ----------\n",
        "def enhance_image(img):\n",
        "    img = ImageEnhance.Contrast(img).enhance(1.4)\n",
        "    img = ImageEnhance.Sharpness(img).enhance(2.1)\n",
        "    img = ImageEnhance.Brightness(img).enhance(1.1)\n",
        "    return img\n",
        "\n",
        "def generate_ai_image(user_prompt):\n",
        "    with torch.autocast(DEVICE) if DEVICE == \"cuda\" else torch.no_grad():\n",
        "        base_img = txt2img(\n",
        "            prompt=user_prompt,\n",
        "            negative_prompt=NEGATIVE_FILTER,\n",
        "            guidance_scale=13,\n",
        "            num_inference_steps=60,\n",
        "            height=IMG_SIZE,\n",
        "            width=IMG_SIZE\n",
        "        ).images[0]\n",
        "\n",
        "    refined_img = img2img(\n",
        "        prompt=user_prompt,\n",
        "        negative_prompt=NEGATIVE_FILTER,\n",
        "        image=base_img.convert(\"RGB\"),\n",
        "        strength=0.65,\n",
        "        guidance_scale=15,\n",
        "        num_inference_steps=80\n",
        "    ).images[0]\n",
        "\n",
        "    refined_img = enhance_image(refined_img)\n",
        "    final_img = refined_img.resize((UPSCALE_SIZE, UPSCALE_SIZE), Image.LANCZOS)\n",
        "\n",
        "    os.makedirs(\"outputs\", exist_ok=True)\n",
        "    file_path = f\"outputs/final_{uuid.uuid4().hex[:8]}.png\"\n",
        "    final_img.save(file_path)\n",
        "\n",
        "    return final_img, file_path\n"
      ],
      "metadata": {
        "id": "NudVnt_eHxtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- GRADIO INTERFACE ----------\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\" Ultra-HD AI Image Generator\")\n",
        "    gr.Markdown(\"High quality Stable Diffusion based image creation system\")\n",
        "\n",
        "    prompt_box = gr.Textbox(\n",
        "        label=\"Describe your image\",\n",
        "        placeholder=\"Example: futuristic city at sunrise, ultra realistic\",\n",
        "        lines=2\n",
        "    )\n",
        "\n",
        "    run_btn = gr.Button(\"Create Image\")\n",
        "\n",
        "    output_img = gr.Image(label=\"Generated Image\")\n",
        "    download = gr.File(label=\"Download\")\n",
        "\n",
        "    run_btn.click(\n",
        "        fn=generate_ai_image,\n",
        "        inputs=prompt_box,\n",
        "        outputs=[output_img, download]\n",
        "    )\n",
        "\n",
        "app.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "-7DLRBezHxxa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
